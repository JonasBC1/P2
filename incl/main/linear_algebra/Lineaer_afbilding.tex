\section{Lineær afbildning}
%
En matrix kan betragtes som en funktion, der afbilder en vektor fra et rum til et andet.
%
\begin{defn}{}{}
Lad $\S _1 \subseteq \R^n$ og $\S _2 \subseteq \R^m$.
En funktion $f$ fra $\S_1$ til $\S_2$, noteret $f:\S_1\rightarrow\S_2$, tildeler enhver vektor $\textbf{v}$ i $\S_1$ en entydig vektor $f(\textbf{v})$ i $\S_2$.
Vektoren $f(\textbf{v})$ kaldes en \textbf{afbildning} af $\textbf{v}$.
%Hedder det codomænet på dansk? Lyder underligt. 
$\S_1$ er \textbf{domænet} for funktionen $f$, mens $\S_2$ kaldes \textbf{codomænet} til $f$.
\textbf{Værdimængden} for $f$ er defineret som mængden af afbildninger $f(\textbf{v})$ for alle $\textbf{v}\in \S_1$.
\end{defn}\noindent
%
Bemærk, afbildning også kaldes transformation.
%potentielt også det super ligegyldige funktionshokuspookus
På figur \ref{fig:afbild} ses, at både $\textbf{u}$ og $\textbf{v}$ har $\textbf{w}$ som afbildning, da $f(\textbf{u})=f(\textbf{v})=\textbf{w}$. \\\\
%
% Lav flot figur som 2.9 på side 167.
%
\input{fig/tikz/dom}
%
\\\\
For funktioner, som er matrix-vektorprodukter, introduceres notationen $T_A$.
%
\begin{defn}{}{fisk3}
Lad $A$ være en $m \times n$ matrix.
Funktionen $T_A:\R^n \rightarrow \R^m$, defineret ved $T_A(\textbf{x}) = A\textbf{x}$ for alle $\textbf{x} \in \R^n$, er en \textbf{matrixafbildning fremkaldt af $\mathbf{A}$.}
\end{defn}\noindent
%
Direkte fra  \ref{thm:mxvpro} ses det, at $T_A$ har egenskaberne $T_A(\textbf{u}+\textbf{v})=T_A(\textbf{u}) + T_A(\textbf{v})$ og $cT_A(\textbf{u}) = T_A(c\textbf{u})$.
Funktioner, der opfylder disse egenskaber, får deres egen definition.
%
\begin{defn}{}{}
Funktionen $T: \R^n \rightarrow \R^m$ er en \textbf{lineær afbildning}, hvis følgende vilkår gør sig gældende for alle $\textbf{u},\textbf{v} \in \R^n$ og alle skalarer $c$:
\begin{enumerate}[label=(\alph*)]
\item $T_A(\textbf{u}+\textbf{v})=T_A(\textbf{u}) + T_A(\textbf{v})$.
\item $cT_A(\textbf{u}) = T_A(c\textbf{u})$.
\end{enumerate}
\end{defn}
\noindent
%
Da matrixafbildninger har disse egenskaber, er alle matrixafbildninger lineære afbildninger.
\ref{thm:afbegen} viser centrale egenskaber ved lineær afbildning.
%Matrixafbildninger er ét ord. 
\newpage 
\begin{thm}{}{afbegen}
Lad $\textbf{u}, \textbf{v} \in \R^n$ og lad $c$ og $k$ være skalarer.
For enhver lineær afbildning $T: \R^n \rightarrow \R^m$ er følgende udsagn sande:
\begin{enumerate}[label = (\alph*)]
\item $T(\textbf{0}) = \textbf{0}$.
\item $T(-\textbf{u}) = -T(\textbf{u})$.
\item $T(\textbf{u}-\textbf{v}) = T(\textbf{u})-T(\textbf{v})$.
\item $T(c\textbf{u} + k\textbf{v}) = cT(\textbf{u}) + kT(\textbf{u})$.
\end{enumerate}
\end{thm}
%
\begin{proof}
\begin{enumerate}[label=(\alph*)]
\item Lad $\textbf{u}, \textbf{v}$ være vektorer i $\R^n$, $c$ og $k$ være skalarer og lad $T: \R^n \rightarrow \R^m$ være en lineær afbildning.
Da $T$ bevarer vektoraddition, haves, at
%
\begin{align*}
T(\textbf{0}) = T(\textbf{0} + \textbf{0}) = T(\textbf{0}) + T(\textbf{0}).
\end{align*}
%
Trækkes $T(\textbf{0})$ fra begge sider, haves, at $\textbf{0} = T(\textbf{0})$.\\
%
\item Da $T$ bevarer skalering, haves
% 
\begin{align*}
T(-\textbf{u}) = T((-1)\textbf{u}) = (-1)T(\textbf{u}) = -T(\textbf{u}).
\end{align*}
%
\item Ved kombination af, at $T$ bevarer vektoraddition og (b), haves, at
%
\begin{align*}
T(\textbf{u}-\textbf{v}) = T(\textbf{u}+(-\textbf{v})) = T(\textbf{u})+T(-\textbf{v}) = T(\textbf{u}) - T(\textbf{v}).
\end{align*}
%
\item Da $T$ både bevarer vektoraddition og skalering, haves, at 
%
\begin{align*}
T(c\textbf{u} + k\textbf{v}) = T(c\textbf{u}) + T(k\textbf{v}) = cT(\textbf{u}) + kT(\textbf{u}).
\end{align*}
%
\end{enumerate}
\end{proof}
%
\\
\ref{thm:afbegen}(d) kan generaliseres til at vise, at lineær afbildning bevarer linearkombinationer.
%Linearkombinationer
\begin{lem}{}{}
Lad $T:\R^n \rightarrow \R^m$ være en lineær afbildning, $\textbf{v}_1,\textbf{v}_2,\ldots,\textbf{v}_k$ være vektorer i $\R^n$ og lad $c_1,c_2,\ldots,c_k$ være skalarer. 
Så gælder, at
%
\begin{align*}
T(c_1\textbf{v}_1 + c_2\textbf{v}_2 + \cdots + c_k\textbf{v}_k) = T(c_1\textbf{v}_1) + T(c_2\textbf{v}_2) + \cdots + T(c_k\textbf{v}_k).
\end{align*}
%
\end{lem}
%
\begin{proof}
Lemmaet følger direkte af \ref{thm:afbegen}(d).
\end{proof}
\\
%
Bemærk, at \ref{thm:afbegen}(a) i nogle tilfælde kan bruges til at vise, at en funktion ikke er lineær. 
Det kan dog forekomme, at en funktion opfylder betingelsen og stadig ikke er lineær.
% 
\\\\
% 
Hvis afbildningen $T$ er lineær, kan en tilsvarende matrix $A$ opstilles, sådan at $T=T_A$, hvilket er belyst i \ref{thm:fisk2}.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 
\begin{thm}{}{fisk2}
Lad $T: \R^n \rightarrow \R^m$ være lineær. 
Hvis der findes en entydig $m \times n$ matrix
\begin{align*}
A= [T(\mathbf{e}_1)\text{    } T(\mathbf{e}_2) \text{    } \ldots \text{    } T(\mathbf{e}_n)],
\end{align*}
hvor søjlerne er afbildninger af $T$ ud fra standardvektorene i $\R^n$, så gælder det, at $T(\mathbf{v})=A \mathbf{v}$ for alle $\mathbf{v} \in \R^n$.
\end{thm}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\begin{proof}
Lad $A= [T(\mathbf{e}_1)\text{    } T(\mathbf{e}_2) \text{    } \ldots \text{    } T(\mathbf{e}_n)]$. 
Den lineære afbildning af $\mathbf{v}$ er
%
\begin{align*}
T(\mathbf{v})= T(v_1 \mathbf{e}_1+v_2 \mathbf{e}_2+ \ldots + v_n \mathbf{e}_n).
\end{align*}
%
Jævnfør \ref{thm:afbegen}(d) er
%
\begin{align*}
T(\mathbf{v})= v_1 T( \mathbf{e}_1)+ v_2 T( \mathbf{e}_2) + \ldots + v_n T( \mathbf{e}_n),
\end{align*}
%
hvilket kan erstattes med elementerne i matrix A, således, at
%
\begin{align*}
T(\mathbf{v})&= v_1 \mathbf{a}_1+ v_2 \mathbf{a}_2 + \ldots + v_n \mathbf{a}_n \\
&= A \mathbf{v}.
\end{align*}
%Er det meningen, at ovenstående skal være på to linjer? 
Jævnfør \ref{defn:fisk3} beviser dette, at
%
\begin{align*}
T(\mathbf{v})= T_A (\mathbf{v}).
\end{align*}\\\\
%
Lad $B$ være en $m \times n$ matrix. 
For at bevise entydigheden, lad da $T_A=T_B$. 
Jævnfør \ref{thm:mxvpro}(e) gælder det, at $A=B$, eftersom $A \mathbf{v}=B \mathbf{v}$ for alle $\mathbf{v}$ i $\R^n$.
\end{proof}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{eks}\label{entydigeks}
%
Lad $T: R^3 \rightarrow R^2$ være defineret ved 
$$T\left(
\begin{bmatrix}
x_1\\
x_2\\
x_3
\end{bmatrix}
\right)
=
\begin{bmatrix}%{[c]}
5x_1+x_2\\
3x_2+2x_3
\end{bmatrix}.
$$ \\
For at danne standardmatricen for $T$, dannes søjlerne 
\begin{align*}
T(\mathbf{e}_1)=
\begin{bmatrix}
5\\
0
\end{bmatrix}\text{, }
T(\mathbf{e}_2)=
\begin{bmatrix}
1\\
3
\end{bmatrix}\text{ og }
T(\mathbf{e}_3)=
\begin{bmatrix}
0\\
2
\end{bmatrix}.
\end{align*}
Derfor er $T = T_A$, hvor
\begin{align*}
A=
\begin{bmatrix}
5 & 1 & 0\\
0 & 3 & 2
\end{bmatrix}.
\end{align*}
\end{eks}